\documentclass[a4paper]{article}

\def\likeLTD{\textsc{LikeLTD}} 

%\VignetteIndexEntry{Using LikeLTD}
\title{Using \likeLTD}
\author{Mayeul d'Avezac}
\author{Christopher Steele}
\author{Adrian Timpson}
\author{James Hetherington}
\author{David Balding}

\begin{document}
\maketitle
<<setthreads, echo=FALSE>>=
  if(.Call(likeLTD::.cpp.nbthreads) > 2) {
    .Call(likeLTD::.cpp.set_nbthreads, as.integer(2))
  }
@

\section{Code usage}

Computing a likehood model takes place in three-parts: (i) creation of the
hypothesis, (ii) creation of the model itself from the hypothesis, (iii)
maximizing the likehood function over the set of nuisance parameters. 

\subsection{Creating a hypothesis}

A hypothesis consists of all the parameters are used to describe the model,
e.~g.\ the known profiles to include, the number of unprofiled contributors,
and whether to include dropin. A proper description of the hypothesis should be
independent of other information, including neither information about the
maximization of the likelihood nor any information which needs to be computed.

<<verystart, eval=FALSE, tidy=FALSE, print=FALSE>>=
  require(likeLTD)
  require(DEoptim)

  # Case we are going to be looking at.
  caseName = 'hammer'
  datapath = file.path(system.file("extdata", package="likeLTD"), 
                       caseName)
  args = list(
    databaseFile = NULL,
    cspFile    = file.path(datapath, 'hammer-CSP.csv'),
    refFile      = file.path(datapath, 'hammer-reference.csv'),
    nUnknowns    = 0,
    doDropin     = TRUE,
    ethnic       = "EA1",
    adj          = 1.0,
    fst          = 0.02,
    relatedness  = c(0, 0)/4
  )
  # Create hypothesis for defence and prosecution.
  defenceHyp = do.call(defence.hypothesis, args)
  prosecuHyp = do.call(prosecution.hypothesis, args)
@

Two methods are provided to facilitate the creation of a hypothesis from a
common minimal set of input parameters, \texttt{defence.hypothesis} for the
defence and \texttt{prosecution.hypothesis} for the prosecution. These two
methods read the allele database, the known profiles, and the crime-scene
profile from file. They also automate sensible default decisions about the
input, (determining which known profiles need be subject to dropout; in the
defence hypothesis the queried individual is replaced by an unprofiled
contributor; in the prosecution case, relatedness is set to zero.) These
default choices may be further modified by the user at this point.  These
methods return lists with all the input needed for model execution. 

<<models, tidy=FALSE, eval=FALSE>>=
  defenceModel <- create.likelihood(defenceHyp)
  prosecuModel <- create.likelihood(prosecuHyp)
@

\texttt{create.likelihood} returns a method which takes as arguments the
nuisance parameters and computes the full weight of evidence, e.~g.\ the
product of the likelihoods and penalties associated with each locus.

<<tidy=FALSE, eval=FALSE>>=
  defenceModel(rcont=c(1, 1e-8, 1.63), 
               degradation=c(10^-2.27, 10^-2.74, 10^-2.47),
               locusAdjustment=list(D3=0.983, vWA=1.010, D16=1.028, 
                                    D2=1.072, D8=1.020, D21=0.930,
                                    D18=0.850, D19=0.932, 
                                    TH01=1.041, FGA=0.916),
               dropout=c(0.5072, 1e-8), 
               dropin=1.0216,
               power=-4.4462)
@

The function above returns a scalar which represents the weight of evidence for
the given values of the nuisance parameters. One could then use
\texttt{defenceModel} to perform an optimisation or to create
a plot with respect to various arguments. For instance, the following leads to
Fig.~\ref{fig:plotme}:

<<plotscalarWoE, tidy=FALSE, eval=FALSE>>=
  require(ggplot2)
  require(scales)
  # Function that winnows down to a single value
  scalarWoE <- function(x) {
     defenceModel(locusAdjustment=list(D3=0.983, vWA=1.010,
                                       D16=1.028, D2=1.072,
                                       D8=1.020, D21=0.930,
                                       D18=0.850, D19=0.932, 
                                       TH01=1.041, FGA=0.916),
                  dropout=c(0.5072, 1e-8), 
                  degradation=c(10^-2.27, 10^-2.74, 10^-2.47),
                  rcont=c(x, 1e-8, 1), 
                  dropin=1.0216,
                  power=-4.4462)
  }

  x = 0:30/30 * 3e0
  data = data.frame(x=x, y=sapply(x, scalarWoE))
  plots <- ggplot(data, aes(x=x, y=y))                  +
              geom_line()                               +
              xlab("Relative contribution of Victim 1") +
              ylab("Weight of Evidence")                +
              scale_y_log10(
                labels=trans_format("log10", math_format(10^.x)))
  print(plots)
@

\begin{figure}[!h]
<<plotme, fig=TRUE, echo=FALSE>>=
<<verystart>>
<<models>>
<<plotscalarWoE>>
@
  \caption{Logarithmic plot of the weight of evidence versus the relative
           contribution from "Victim 1". The likelihood is for the Hammer case,
           with one unprofiled contributor ("X"), and including dropin. The
           fixed parameters are given in Tab.~\ref{tab:maxi}. }
  \label{fig:plotme}
\end{figure}

\subsection{Maximizing the likehood}

Once we have a likelihood method, it is possible to use the \texttt{stats}
package to maximize it. However, the likelihood method takes several arguments
(\texttt{rcont}, \texttt{degradation}, etc), whereas \texttt{stats::optim}
expects a methods which takes only a vector as argument. Hence, we need to
transform our method into the form the optimisation method expects:

<<skel, eval=FALSE, tidy=FALSE>>=
  skeleton = initial.arguments(defenceHyp)
  vector.model <- function(x) {
    args <- relist(x, skeleton)
    args[["degradation"]] = 10^args[["degradation"]]
    result <- do.call(defenceModel, args)
    log10(result)
  }

  # Call vector.model with vector argument.
  arguments = skeleton
  arguments[["degradation"]] = log10(arguments[["degradation"]])
  vector.model( as.vector(unlist(arguments)) )
@

The new method \texttt{vectorModel} achieves three objectives: (i) it recreates the
list of arguments for \texttt{defenceModel}, (ii) it transforms the degradation
parameter from an exponential form, (iii) it takes the logarithm of the weight
of evidence. The last two points make optimisation somewhat easier. We can now
apply the optimisation methods on \texttt{vectorModel}.

<<maxiskel, eval=FALSE, tidy=FALSE>>=
  require(stats)
  # define upper and lower bounds for constrained maximization
  nloci = ncol(defenceHyp$cspProfile)
  upper = list(locusAdjustment = rep(1.5, nloci),
               dropout         = c(1-1e-3, 1-1e-3),
               degradation     = rep(-1e-3, 3),
               rcont           = rep(100, 2),
               dropin          = 1,
               power      = -2 )[names(arguments)]
  lower = list(locusAdjustment = rep(0.5, nloci),
               dropout         = c(1e-3, 1e-3),
               degradation     = rep(-20, 3),
               rcont           = rep(1e-3, 2),
               dropin          = 1e-3,
               power      = -6 )[names(arguments)]

  # perform maximization
  result <- DEoptim(fn  = vector.model,
                  upper = unlist(upper),
                  lower = unlist(lower),
                  control = list(strategy=3, itermax=500)
  		)
  opti = relist(result$optim$bestmem, skeleton)
  cat(sprintf("Resulting Weight of Evidence: 10^%f\n",
              -result$optim$bestval))
@
<<alltheabove, echo=FALSE>>=
<<verystart>>
<<models>>
<<skel>>
<<maxiskel>>
@

The above calculates the maximum of the likelihood using a conjugate gradient
method. The particular flavor of conjugate-gradient used here allows the user
to set upper and lower bounds for parameters. The \texttt{stats::optim}
computes the derivatives of \texttt{vector.model} numerically. Upon
convergence, it returns a list with the optimum and its location. Please see
the \texttt{stat} package for description.

The functionality of the above code can be achieved more succinctly through a
convenience method provided by \likeLTD\, \texttt{optimisation.params}. It
returns a list of adequate arguments for \texttt{optim} given a hypothesis:

<<optim, eval=FALSE, tidy=FALSE>>=
  params = optimisation.params(defenceHyp, verbose=FALSE)
  params$control$itermax=50 # Less strict convergence, for demo purposes.
  results <- do.call(DEoptim, params)
  arguments <- relistArguments(results$optim$bestmem, defenceHyp)
@

Running the above yields the parameters in Tab.~\ref{tab:maxi}. The last line
transforms the linear vector of arguments returned by \texttt{optim} back into
a more meaningful list, much as \texttt{relist} did earlier. However, it takes
care of some specialized problems with the operation, and should be preferred
over \texttt{relist}.
\begin{table}
<<tabopt, echo=FALSE>>=
<<verystart>>
<<optim>>
@
\begin{tabular}{l|ccc}
  \hline
              & Victim 1 & Victim 2 & X \\\hline
  rcont & \Sexpr{paste(format(c(1, arguments$rcont), digits=3), collapse="&", sep="")} \\
  degradation & $10^{\Sexpr{format(arguments[["degradation"]][[1]], digits=3)}}$ &
                $10^{\Sexpr{format(arguments[["degradation"]][[2]], digits=3)}}$ &
                $10^{\Sexpr{format(arguments[["degradation"]][[3]], digits=3)}}$ \\\hline
\end{tabular}\\[2ex]

\begin{tabular}{ccccc}
  \hline
  \multicolumn{5}{c}{Locus Ajustments for each locus}\\\hline
  \Sexpr{paste(colnames(defenceHyp$cspProfile)[1:5], collapse=" & ", sep="")}\\
  \Sexpr{paste(format(arguments$locusAdjustment[1:5], digits=3), collapse=" & ", sep="")}\\\hline
  \Sexpr{paste(colnames(defenceHyp$cspProfile)[6:10], collapse=" & ", sep="")}\\
  \Sexpr{paste(format(arguments$locusAdjustment[6:10], digits=3), collapse=" & ", sep="")}\\\hline
\end{tabular}\\[2ex]

\begin{tabular}{l|cc}
  \hline
              & First Replicate & Second Replicate \\\hline
  dropout     & \Sexpr{format(arguments$dropout[[1]], digits=3)}
              & \Sexpr{format(arguments$dropout[[2]], digits=3)} \\\hline
\end{tabular}\\[2ex]

\begin{tabular}{l|c}
  \hline
  dropin      & \Sexpr{format(arguments$dropin, digits=3)} \\
  power  & \Sexpr{format(arguments$power, digits=3)}\\\hline
\end{tabular}

  \caption{Arguments at the maximum for the defence hypothesis of the Hammer
  case, with dropin and a single unprofiled contributor X. The optimum is
  obtained by running the external function \texttt{stats::optim} directly on
  the objective function generated by \likeLTD. }\label{tab:maxi}
\end{table}


\subsection{Testing}

\likeLTD comes a fairly extensive suite of tests. The tests can be run as part
of the installation process, or using the following commands:

<<testing, tidy=FALSE, eval=FALSE>>=
library(svUnit)
library(likeLTD)

runTest( svSuite("package:likeLTD") )
Log()
@
Although not shown here, this snippet will print results for each tests. Each
should return "OK".

\end{document}
